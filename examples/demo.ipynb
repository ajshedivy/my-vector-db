{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Vector Database - Demo\n",
    "\n",
    "A lightweight, production-ready vector database with a RESTful API and Python SDK\n",
    "\n",
    "**Topics Covered**:\n",
    "1. Architecture Overview\n",
    "2. Creating Data\n",
    "3. Reading & Updating\n",
    "4. Vector Search\n",
    "5. Filtering\n",
    "6. Persistence\n",
    "7. Agno Integration\n",
    "8. Design Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Architecture Overview\n",
    "\n",
    "The vector database is organized in a **3-tier hierarchy**:\n",
    "- **Libraries**: Top-level containers with vector index configuration\n",
    "- **Documents**: Logical groupings within a library\n",
    "- **Chunks**: Individual searchable units with text, embeddings, and metadata\n",
    "\n",
    "![alt text](../docs/data_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection & Validation\n",
    "\n",
    "First, verify the API server is running and check initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'healthy',\n",
       " 'service': 'vector-db',\n",
       " 'version': '0.1.0',\n",
       " 'storage': {'libraries': 1, 'documents': 7, 'chunks': 7}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_vector_db.sdk import VectorDBClient\n",
    "\n",
    "client = VectorDBClient(base_url=\"http://localhost:8000\")\n",
    "\n",
    "# Validate connection and check initial state\n",
    "status = client.get_health_status()\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Creating Data: Hierarchical Structure\n",
    "\n",
    "The hierarchical design allows flexible organization:\n",
    "- **Libraries** define index configuration (FLAT, HNSW) and distance metrics\n",
    "- **Documents** group related chunks (e.g., chapters in a book)\n",
    "- **Chunks** are the actual searchable units with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created library: 84aed1c8-9272-4a35-8f7e-e0e47f231212\n",
      "Index type: IndexType.FLAT\n",
      "Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# Create library with index configuration\n",
    "library = client.create_library(\n",
    "    name=\"my_demo_library\",\n",
    "    index_type=\"flat\",\n",
    "    index_config={\"metric\": \"cosine\"},\n",
    "    metadata={\"description\": \"Sample library\", \"version\": \"1.0\"},\n",
    ")\n",
    "\n",
    "print(f\"Created library: {library.id}\")\n",
    "print(f\"Index type: {library.index_type}\")\n",
    "print(f\"Metric: {library.index_config['metric']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created document: 97601ceb-4397-4e2c-904f-00fa900dfb91\n",
      "Name: demo_document\n"
     ]
    }
   ],
   "source": [
    "# Create document within library\n",
    "document = client.create_document(\n",
    "    library_id=library.id,\n",
    "    name=\"demo_document\",\n",
    "    metadata={\"year\": 2024, \"source\": \"tech blogs\"},\n",
    ")\n",
    "\n",
    "print(f\"Created document: {document.id}\")\n",
    "print(f\"Name: {document.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(id=UUID('24840eb0-0138-4d12-8ca8-c1b148bfbfce'), text='The quick brown fox jumps over the lazy dog', embedding=[0.1, 0.2, 0.3, 0.4, 0.5], metadata={'source': 'example', 'position': 1}, document_id=UUID('97601ceb-4397-4e2c-904f-00fa900dfb91'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 950485), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 950485)),\n",
       " Chunk(id=UUID('d0b822a9-6e5e-41d6-8253-454a0e7a42bf'), text='A fast red bird flies through the clear blue sky', embedding=[0.9, 0.1, 0.5, 0.3, 0.7], metadata={'source': 'example', 'position': 2}, document_id=UUID('97601ceb-4397-4e2c-904f-00fa900dfb91'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 950496), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 950496))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_vector_db import Chunk\n",
    "\n",
    "# Define chunks with Chunk objects\n",
    "demo_chunks = [\n",
    "    Chunk(\n",
    "        document_id=document.id,\n",
    "        text=\"The quick brown fox jumps over the lazy dog\",\n",
    "        embedding=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        metadata={\"source\": \"example\", \"position\": 1}\n",
    "    ),\n",
    "    Chunk(\n",
    "        document_id=document.id,\n",
    "        text=\"A fast red bird flies through the clear blue sky\",\n",
    "        embedding=[0.9, 0.1, 0.5, 0.3, 0.7],\n",
    "        metadata={\"source\": \"example\", \"position\": 2}\n",
    "    )\n",
    "]\n",
    "\n",
    "client.add_chunks(chunks=demo_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated all chunks with review metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chunk(id=UUID('24840eb0-0138-4d12-8ca8-c1b148bfbfce'), text='The quick brown fox jumps over the lazy dog', embedding=[0.1, 0.2, 0.3, 0.4, 0.5], metadata={'source': 'example', 'position': 1, 'reviewed_by': 'demo_bot'}, document_id=UUID('97601ceb-4397-4e2c-904f-00fa900dfb91'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 950485), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 960591))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for chunk in client.list_chunks(document_id=document.id):\n",
    "    chunk.metadata[\"reviewed_by\"] = \"demo_bot\"\n",
    "    client.update_chunk(chunk)\n",
    "\n",
    "print(\"Updated all chunks with review metadata\")\n",
    "\n",
    "# Verify update\n",
    "sample = client.list_chunks(document_id=document.id)[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=UUID('97601ceb-4397-4e2c-904f-00fa900dfb91'), name='demo_document_v2', chunk_ids=[UUID('24840eb0-0138-4d12-8ca8-c1b148bfbfce'), UUID('d0b822a9-6e5e-41d6-8253-454a0e7a42bf')], metadata={'year': 2024, 'source': 'tech blogs'}, library_id=UUID('84aed1c8-9272-4a35-8f7e-e0e47f231212'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 942356), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 38, 968985))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update document name\n",
    "client.update_document(document=document.id, name=\"demo_document_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete document: cascade deletes chunks too\n",
    "client.delete_document(document_id=document.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset\n",
    "\n",
    "This dataset includes:\n",
    "- **7 articles (chunks)** across 3 categories (AI, Cloud, Security)\n",
    "- **Rich metadata**: category, topic, confidence scores, authors\n",
    "- **5D embeddings**: Simplified for demo purposes (production typically uses 768-1536 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 7 chunks\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "    # AI/ML chunks\n",
    "    {\n",
    "        \"text\": \"Machine learning models use neural networks for pattern recognition\",\n",
    "        \"embedding\": [0.9, 0.8, 0.1, 0.2, 0.3],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"machine learning\",\n",
    "            \"confidence\": 0.95,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Deep learning architectures enable complex AI applications\",\n",
    "        \"embedding\": [0.85, 0.75, 0.15, 0.25, 0.35],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"deep learning\",\n",
    "            \"confidence\": 0.88,\n",
    "            \"author\": \"Bob\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Reinforcement learning enables autonomous decision making\",\n",
    "        \"embedding\": [0.87, 0.77, 0.13, 0.23, 0.33],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"reinforcement learning\",\n",
    "            \"confidence\": 0.90,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    # Cloud computing chunks\n",
    "    {\n",
    "        \"text\": \"Cloud infrastructure provides scalable computing resources\",\n",
    "        \"embedding\": [0.3, 0.2, 0.9, 0.8, 0.1],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"cloud\",\n",
    "            \"topic\": \"infrastructure\",\n",
    "            \"confidence\": 0.92,\n",
    "            \"author\": \"Charlie\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Kubernetes orchestrates containerized applications in the cloud\",\n",
    "        \"embedding\": [0.35, 0.25, 0.85, 0.75, 0.15],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"cloud\",\n",
    "            \"topic\": \"kubernetes\",\n",
    "            \"confidence\": 0.89,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    # Security chunks\n",
    "    {\n",
    "        \"text\": \"Cybersecurity best practices protect against data breaches\",\n",
    "        \"embedding\": [0.1, 0.2, 0.3, 0.9, 0.8],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"security\",\n",
    "            \"topic\": \"cybersecurity\",\n",
    "            \"confidence\": 0.91,\n",
    "            \"author\": \"Bob\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Machine learning detects anomalies in network security\",\n",
    "        \"embedding\": [0.6, 0.5, 0.4, 0.7, 0.6],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"security\",\n",
    "            \"topic\": \"machine learning\",\n",
    "            \"confidence\": 0.82,\n",
    "            \"author\": \"Charlie\",\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created library: 5fbbba2b-ca18-4ad0-8aae-a652c3a5de76\n",
      "Index type: IndexType.FLAT\n",
      "Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# Create library with index configuration\n",
    "library = client.create_library(\n",
    "    name=\"tech_articles\",\n",
    "    index_type=\"flat\",\n",
    "    index_config={\"metric\": \"cosine\"},\n",
    "    metadata={\"description\": \"Technology articles\", \"version\": \"1.0\"},\n",
    ")\n",
    "\n",
    "print(f\"Created library: {library.id}\")\n",
    "print(f\"Index type: {library.index_type}\")\n",
    "print(f\"Metric: {library.index_config['metric']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    new_doc = client.create_document(\n",
    "        library_id=library.id,\n",
    "        name=f\"doc_{i+1}\",\n",
    "        metadata={\"source\": \"demo_dataset\"},\n",
    "    )\n",
    "    client.add_chunks(chunks=[chunk], document_id=new_doc.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Insert\n",
    "\n",
    "**Design Pattern**: Batch operations are preferred over individual inserts.\n",
    "\n",
    "**Benefits**:\n",
    "- Single API call reduces HTTP round-trips\n",
    "- Atomic transactions (all-or-nothing)\n",
    "- Better performance for large datasets\n",
    "\n",
    "**Best Practice**: Always use `add_chunks()` for multiple inserts tyo single document rather than looping with individual `add_chunk()` calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 7 chunks\n",
      "Sample: Machine learning models use neural networks for pa...\n"
     ]
    }
   ],
   "source": [
    "# Batch insert all chunks at once\n",
    "my_doc = client.create_document(\n",
    "    library_id=library.id,\n",
    "    name=\"batch_doc\",\n",
    "    metadata={\"source\": \"demo_dataset\"},\n",
    ")\n",
    "chunks = client.add_chunks(document_id=my_doc.id, chunks=chunks)\n",
    "\n",
    "print(f\"Inserted {len(chunks)} chunks\")\n",
    "print(f\"Sample: {chunks[0].text[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reading & Updating Data\n",
    "\n",
    "After creation, all entities can be accessed by their parent UUID. This simplifies API usage while maintaining referential integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries: 3\n",
      "Documents: 8\n",
      "Chunks: 14\n"
     ]
    }
   ],
   "source": [
    "# List operations at each level\n",
    "libraries = client.list_libraries()\n",
    "print(f\"Libraries: {len(libraries)}\")\n",
    "\n",
    "documents = client.list_documents(library_id=library.id)\n",
    "print(f\"Documents: {len(documents)}\")\n",
    "\n",
    "chunks = client.list_all_chunks(library_id=library.id)\n",
    "print(f\"Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Operations\n",
    "\n",
    "Updates are performed on full objects. Notice how the `updated_at` timestamp changes while `created_at` remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated all chunks with review metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Chunk(id=UUID('82bce628-36e7-4f30-97de-b2ffdf6451cc'), text='Machine learning models use neural networks for pattern recognition', embedding=[0.9, 0.8, 0.1, 0.2, 0.3], metadata={'category': 'ai', 'topic': 'machine learning', 'confidence': 0.95, 'author': 'Alice', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14387), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 54390)),\n",
       " Chunk(id=UUID('eeedae02-f631-45da-89f3-8fdba9946bcf'), text='Deep learning architectures enable complex AI applications', embedding=[0.85, 0.75, 0.15, 0.25, 0.35], metadata={'category': 'ai', 'topic': 'deep learning', 'confidence': 0.88, 'author': 'Bob', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14392), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 55300)),\n",
       " Chunk(id=UUID('09026f40-714c-4563-be18-013965b36b9f'), text='Reinforcement learning enables autonomous decision making', embedding=[0.87, 0.77, 0.13, 0.23, 0.33], metadata={'category': 'ai', 'topic': 'reinforcement learning', 'confidence': 0.9, 'author': 'Alice', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14395), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 56245)),\n",
       " Chunk(id=UUID('a02ce66c-78d8-4f5e-a46d-318e45c828af'), text='Cloud infrastructure provides scalable computing resources', embedding=[0.3, 0.2, 0.9, 0.8, 0.1], metadata={'category': 'cloud', 'topic': 'infrastructure', 'confidence': 0.92, 'author': 'Charlie', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14398), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 57324)),\n",
       " Chunk(id=UUID('1eb0d6ef-3b45-4979-97ed-eefd12a07bbf'), text='Kubernetes orchestrates containerized applications in the cloud', embedding=[0.35, 0.25, 0.85, 0.75, 0.15], metadata={'category': 'cloud', 'topic': 'kubernetes', 'confidence': 0.89, 'author': 'Alice', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14400), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 58319)),\n",
       " Chunk(id=UUID('8f49c0c7-fc69-43fb-9cda-034b02b67be6'), text='Cybersecurity best practices protect against data breaches', embedding=[0.1, 0.2, 0.3, 0.9, 0.8], metadata={'category': 'security', 'topic': 'cybersecurity', 'confidence': 0.91, 'author': 'Bob', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14403), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 59252)),\n",
       " Chunk(id=UUID('30ca7d28-d133-4ad0-a878-d7ddef49e5aa'), text='Machine learning detects anomalies in network security', embedding=[0.6, 0.5, 0.4, 0.7, 0.6], metadata={'category': 'security', 'topic': 'machine learning', 'confidence': 0.82, 'author': 'Charlie', 'reviewed_by': 'demo_bot'}, document_id=UUID('d2bbe16e-9c5f-4a0d-9f85-987700dce22c'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 14405), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 39, 60419))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update metadata on all chunks\n",
    "documents = client.list_documents(library_id=library.id)\n",
    "for document in documents:\n",
    "    for chunk in client.list_chunks(document_id=document.id):\n",
    "        chunk.metadata[\"reviewed_by\"] = \"demo_bot\"\n",
    "        client.update_chunk(chunk)\n",
    "\n",
    "print(\"Updated all chunks with review metadata\")\n",
    "\n",
    "# Verify update\n",
    "sample = client.list_chunks(document_id=documents[-1].id)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Vector Search\n",
    "\n",
    "The vector database performs **k-nearest neighbor (kNN)** search using the configured distance metric.\n",
    "\n",
    "**Current Implementation**: FLAT index\n",
    "- **Complexity**: O(n) - exhaustive search\n",
    "- **Recall**: 100% (exact search, guaranteed true nearest neighbors)\n",
    "- **Best for**: < 10,000 vectors\n",
    "\n",
    "**Alternative**: HNSW index (planned)\n",
    "- **Complexity**: O(log n) - approximate search\n",
    "- **Recall**: ~95-99% (tunable)\n",
    "- **Best for**: Millions of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query time: 0.81ms\n",
      "Searched 5 chunks\n",
      "Index type: IndexType.FLAT\n",
      "\n",
      "1. Score: 0.9999\n",
      "   Reinforcement learning enables autonomous decision making\n",
      "   Category: ai\n",
      "   Document: doc_3\n",
      "\n",
      "2. Score: 0.9999\n",
      "   Reinforcement learning enables autonomous decision making\n",
      "   Category: ai\n",
      "   Document: batch_doc\n",
      "\n",
      "3. Score: 0.9995\n",
      "   Machine learning models use neural networks for pattern recognition\n",
      "   Category: ai\n",
      "   Document: doc_1\n",
      "\n",
      "4. Score: 0.9995\n",
      "   Machine learning models use neural networks for pattern recognition\n",
      "   Category: ai\n",
      "   Document: batch_doc\n",
      "\n",
      "5. Score: 0.9987\n",
      "   Deep learning architectures enable complex AI applications\n",
      "   Category: ai\n",
      "   Document: doc_2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query about AI/ML topics\n",
    "query_vector = [0.88, 0.78, 0.12, 0.22, 0.32]\n",
    "\n",
    "search_results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(f\"Query time: {search_results.query_time_ms:.2f}ms\")\n",
    "print(f\"Searched {len(search_results.results)} chunks\")\n",
    "print(f\"Index type: {library.index_type}\\n\")\n",
    "\n",
    "for i, result in enumerate(search_results.results, 1):\n",
    "    print(f\"{i}. Score: {result.score:.4f}\")\n",
    "    print(f\"   {result.text}\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Document: {client.get_document(result.document_id).name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new chunk and rebuild index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BuildIndexResult(library_id=UUID('5fbbba2b-ca18-4ad0-8aae-a652c3a5de76'), total_vectors=15, dimension=5, index_type=<IndexType.FLAT: 'flat'>, index_config={'metric': 'cosine'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = client.create_document(\n",
    "    library_id=library.id,\n",
    "    name=\"additional_ai_article\",\n",
    "    metadata={\"year\": 2024, \"source\": \"tech blogs\"},\n",
    ")\n",
    "\n",
    "new_chunk = Chunk(\n",
    "    document_id=new_doc.id,\n",
    "    text=\"AI is super cool\",\n",
    "    embedding=[0.8, 0.78, 0.12, 0.22, 0.3],\n",
    "    metadata={\n",
    "        \"category\": \"ai\",\n",
    "        \"topic\": \"machine learning\",\n",
    "        \"confidence\": 0.95,\n",
    "        \"author\": \"Alice\",\n",
    "    },\n",
    ")\n",
    "\n",
    "client.add_chunk(chunk=new_chunk, document_id=new_doc.id)\n",
    "\n",
    "build_index_response = client.build_index(library_id=library.id)\n",
    "build_index_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query time: 0.15ms\n",
      "Searched 5 chunks\n",
      "Index type: IndexType.FLAT\n",
      "\n",
      "1. Score: 0.9999\n",
      "   Reinforcement learning enables autonomous decision making\n",
      "   Category: ai\n",
      "   Document: doc_3\n",
      "\n",
      "2. Score: 0.9999\n",
      "   Reinforcement learning enables autonomous decision making\n",
      "   Category: ai\n",
      "   Document: batch_doc\n",
      "\n",
      "3. Score: 0.9995\n",
      "   Machine learning models use neural networks for pattern recognition\n",
      "   Category: ai\n",
      "   Document: doc_1\n",
      "\n",
      "4. Score: 0.9995\n",
      "   Machine learning models use neural networks for pattern recognition\n",
      "   Category: ai\n",
      "   Document: batch_doc\n",
      "\n",
      "5. Score: 0.9989\n",
      "   AI is super cool\n",
      "   Category: ai\n",
      "   Document: additional_ai_article\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same query after adding new chunk\n",
    "query_vector = [0.88, 0.78, 0.12, 0.22, 0.32]\n",
    "\n",
    "# index is automatically updated\n",
    "search_results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "print(f\"Query time: {search_results.query_time_ms:.2f}ms\")\n",
    "print(f\"Searched {len(search_results.results)} chunks\")\n",
    "print(f\"Index type: {library.index_type}\\n\")\n",
    "\n",
    "for i, result in enumerate(search_results.results, 1):\n",
    "    print(f\"{i}. Score: {result.score:.4f}\")\n",
    "    print(f\"   {result.text}\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Document: {client.get_document(result.document_id).name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Filtering: Two Approaches\n",
    "\n",
    "The SDK provides two complementary filtering strategies:\n",
    "\n",
    "### Approach 1: Custom Functions (SDK-Only)\n",
    "- **Python functions** for maximum flexibility\n",
    "- **Client-side** filtering with access to similarity scores\n",
    "- Complex logic without API changes\n",
    "- **Use for**: Common filtering scenarios, prototyping\n",
    "\n",
    "### Approach 2: Declarative Filters (API-Compatible)\n",
    "- **JSON-serializable** filter definitions\n",
    "- **Server-side** filtering via REST API\n",
    "- Works with any HTTP client\n",
    "- **Use for**: Advanced use cases, production deployments, cross-language clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Filter Functions (SDK Only)\n",
    "\n",
    "For complex filtering logic, pass a Python function to `filter_function`. The function receives `SearchResult` objects (not `Chunk` objects), which include the similarity score.\n",
    "\n",
    "**Implementation Detail**: \n",
    "- Uses over-fetch strategy (kÃ—3) to compensate for client-side filtering\n",
    "- Operates on `SearchResult` to avoid circular dependencies\n",
    "- Enables filtering based on similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by category='ai':\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making...\n",
      "   Category: ai\n",
      "   Score: 0.9999\n",
      "2. Reinforcement learning enables autonomous decision making...\n",
      "   Category: ai\n",
      "   Score: 0.9999\n",
      "3. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n",
      "4. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n",
      "5. AI is super cool...\n",
      "   Category: ai\n",
      "   Score: 0.9989\n"
     ]
    }
   ],
   "source": [
    "query_vector = [0.88, 0.78, 0.12, 0.22, 0.32]\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filter_function=lambda chunk: chunk.metadata.get(\"category\") == \"ai\"\n",
    ")\n",
    "\n",
    "print(\"Filtered by category='ai':\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text[:60]}...\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Score: {result.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by (AI AND confidence>0.9) OR security:\n",
      "\n",
      "1. [ai] Machine learning models use neural networks for pa...\n",
      "   Confidence: 0.95, Score: 0.9995\n",
      "\n",
      "2. [ai] Machine learning models use neural networks for pa...\n",
      "   Confidence: 0.95, Score: 0.9995\n",
      "\n",
      "3. [ai] AI is super cool...\n",
      "   Confidence: 0.95, Score: 0.9989\n",
      "\n",
      "4. [security] Machine learning detects anomalies in network secu...\n",
      "   Confidence: 0.82, Score: 0.8285\n",
      "\n",
      "5. [security] Machine learning detects anomalies in network secu...\n",
      "   Confidence: 0.82, Score: 0.8285\n",
      "\n",
      "6. [security] Cybersecurity best practices protect against data ...\n",
      "   Confidence: 0.91, Score: 0.4679\n",
      "\n",
      "7. [security] Cybersecurity best practices protect against data ...\n",
      "   Confidence: 0.91, Score: 0.4679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.sdk.models import SearchResult\n",
    "\n",
    "\n",
    "def complex_filter_function(result: SearchResult):\n",
    "    \"\"\"\n",
    "    Returns True for:\n",
    "    - High-confidence AI articles (category='ai' AND confidence > 0.9)\n",
    "    - OR any security article (category='security')\n",
    "    \"\"\"\n",
    "    category = result.metadata.get(\"category\")\n",
    "    confidence = result.metadata.get(\"confidence\")\n",
    "\n",
    "    # High-confidence AI articles\n",
    "    is_high_confidence_ai = (\n",
    "        category == \"ai\" and confidence is not None and confidence > 0.9\n",
    "    )\n",
    "\n",
    "    # Any security article\n",
    "    is_security = category == \"security\"\n",
    "\n",
    "    # OR logic: either condition passes\n",
    "    return is_high_confidence_ai or is_security\n",
    "\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=10,\n",
    "    filter_function=complex_filter_function,\n",
    ")\n",
    "\n",
    "print(\"Filtered by (AI AND confidence>0.9) OR security:\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. [{result.metadata['category']}] {result.text[:50]}...\")\n",
    "    print(\n",
    "        f\"   Confidence: {result.metadata['confidence']}, Score: {result.score:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom filter: high score, AI, Alice, high confidence\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making\n",
      "   Score: 0.9999, Confidence: 0.9\n",
      "\n",
      "2. Reinforcement learning enables autonomous decision making\n",
      "   Score: 0.9999, Confidence: 0.9\n",
      "\n",
      "3. Machine learning models use neural networks for pattern recognition\n",
      "   Score: 0.9995, Confidence: 0.95\n",
      "\n",
      "4. Machine learning models use neural networks for pattern recognition\n",
      "   Score: 0.9995, Confidence: 0.95\n",
      "\n",
      "5. AI is super cool\n",
      "   Score: 0.9989, Confidence: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.sdk.models import SearchResult\n",
    "\n",
    "\n",
    "# Custom filter combining multiple conditions\n",
    "def high_quality_ai_by_alice(result: SearchResult) -> bool:\n",
    "    return (\n",
    "        result.score > 0.95\n",
    "        and result.metadata.get(\"category\") == \"ai\"\n",
    "        and result.metadata.get(\"author\") == \"Alice\"\n",
    "        and result.metadata.get(\"confidence\", 0) > 0.85\n",
    "    )\n",
    "\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filter_function=high_quality_ai_by_alice,\n",
    ")\n",
    "\n",
    "print(\"Custom filter: high score, AI, Alice, high confidence\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text}\")\n",
    "    print(\n",
    "        f\"   Score: {result.score:.4f}, Confidence: {result.metadata['confidence']}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarative Filters (API-Compatible)\n",
    "\n",
    "For complex filtering logic, use JSON-serializable filter definitions. These filters are processed server-side, ensuring compatibility with any HTTP client.\n",
    "\n",
    "- Supports logical operators (AND, OR, NOT) and comparison operators (==, !=, <, <=, >, >=)\n",
    "- Enables filtering based on chunk metadata without custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by category='ai':\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making...\n",
      "   Category: ai\n",
      "   Score: 0.9999\n",
      "2. Reinforcement learning enables autonomous decision making...\n",
      "   Category: ai\n",
      "   Score: 0.9999\n",
      "3. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n",
      "4. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n",
      "5. AI is super cool...\n",
      "   Category: ai\n",
      "   Score: 0.9989\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.domain.models import (\n",
    "    SearchFilters,\n",
    "    FilterGroup,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    "    LogicalOperator,\n",
    ")\n",
    "\n",
    "# Simple metadata filter\n",
    "filters = SearchFilters(\n",
    "    metadata=FilterGroup(\n",
    "        filters=[\n",
    "            MetadataFilter(field=\"category\", operator=FilterOperator.EQUALS, value=\"ai\")\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "print(\"Filtered by category='ai':\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text[:60]}...\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Score: {result.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex AND/OR Filters\n",
    "\n",
    "Filters support nested logic for sophisticated queries. This example finds:\n",
    "- (AI articles with confidence > 0.9) **OR** (any security article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by (AI AND confidence>0.9) OR security:\n",
      "\n",
      "1. [ai] Machine learning models use neural networks for pa...\n",
      "   Confidence: 0.95, Score: 0.9995\n",
      "\n",
      "2. [ai] Machine learning models use neural networks for pa...\n",
      "   Confidence: 0.95, Score: 0.9995\n",
      "\n",
      "3. [ai] AI is super cool...\n",
      "   Confidence: 0.95, Score: 0.9989\n",
      "\n",
      "4. [security] Machine learning detects anomalies in network secu...\n",
      "   Confidence: 0.82, Score: 0.8285\n",
      "\n",
      "5. [security] Machine learning detects anomalies in network secu...\n",
      "   Confidence: 0.82, Score: 0.8285\n",
      "\n",
      "6. [security] Cybersecurity best practices protect against data ...\n",
      "   Confidence: 0.91, Score: 0.4679\n",
      "\n",
      "7. [security] Cybersecurity best practices protect against data ...\n",
      "   Confidence: 0.91, Score: 0.4679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_filters = SearchFilters(\n",
    "    metadata=FilterGroup(\n",
    "        operator=LogicalOperator.OR,\n",
    "        filters=[\n",
    "            # High-confidence AI articles\n",
    "            FilterGroup(\n",
    "                operator=LogicalOperator.AND,\n",
    "                filters=[\n",
    "                    MetadataFilter(\n",
    "                        field=\"category\", operator=FilterOperator.EQUALS, value=\"ai\"\n",
    "                    ),\n",
    "                    MetadataFilter(\n",
    "                        field=\"confidence\",\n",
    "                        operator=FilterOperator.GREATER_THAN,\n",
    "                        value=0.9,\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "            # OR any security article\n",
    "            MetadataFilter(\n",
    "                field=\"category\", operator=FilterOperator.EQUALS, value=\"security\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=10,\n",
    "    filters=complex_filters,\n",
    ")\n",
    "\n",
    "print(\"Filtered by (AI AND confidence>0.9) OR security:\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. [{result.metadata['category']}] {result.text[:50]}...\")\n",
    "    print(\n",
    "        f\"   Confidence: {result.metadata['confidence']}, Score: {result.score:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Filters\n",
    "You can also combine both declarative filters and custom filter functions using the `SearchFiltersWithCallable` class. This allows you to leverage the strengths of both approaches in a single search operation.\n",
    "\n",
    "- filter metatdata category is \"ai\" on the server side\n",
    "- filter returned results to only those containing the word \"pattern\" on the client side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by category='ai' and containing 'pattern':\n",
      "\n",
      "1. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n",
      "2. Machine learning models use neural networks for pattern reco...\n",
      "   Category: ai\n",
      "   Score: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Simple metadata filter\n",
    "from my_vector_db.domain.models import SearchFiltersWithCallable\n",
    "\n",
    "\n",
    "filters = SearchFiltersWithCallable(\n",
    "    metadata=FilterGroup(\n",
    "        filters=[\n",
    "            MetadataFilter(field=\"category\", operator=FilterOperator.EQUALS, value=\"ai\")\n",
    "        ],\n",
    "    ),\n",
    "    custom_filter=lambda r: \"pattern\" in r.text.lower()\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    combined_filters=filters,\n",
    ")\n",
    "\n",
    "print(\"Filtered by category='ai' and containing 'pattern':\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text[:60]}...\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Score: {result.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: 3f0b52d1-4e46-4185-9533-cf382efae09c, Name: doc_1\n",
      "Document 2: 3c95f54d-7faf-4238-b2c6-a0be5e4210d7, Name: doc_2\n",
      "Filtered by docs:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = client.list_documents(library_id=library.id)\n",
    "doc1 = client.get_document(docs[0].id)\n",
    "doc2 = client.get_document(docs[1].id)\n",
    "print(f\"Document 1: {doc1.id}, Name: {doc1.name}\")\n",
    "print(f\"Document 2: {doc2.id}, Name: {doc2.name}\")\n",
    "\n",
    "doc_filter = SearchFilters(\n",
    "    document_ids=[doc1.id, doc2.id]\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filters=doc_filter,\n",
    ")\n",
    "print(\"Filtered by docs:\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text[:60]}...\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Score: {result.score:.4f}\")\n",
    "    print(f\"   Document: {client.get_document(result.document_id).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Persistence & Durability\n",
    "\n",
    "The database supports optional persistence with a simple snapshot-based approach.\n",
    "\n",
    "**Design Decision**: JSON snapshots\n",
    "- Saves entire state to JSON every N operations (default: 10)\n",
    "- Atomic writes using temp file + rename pattern\n",
    "- Human-readable format for debugging\n",
    "- Configurable via environment variables\n",
    "\n",
    "**Tradeoff**: \n",
    "- **Pro**: Simple implementation, easy debugging, no threading complexity\n",
    "- **Con**: May lose last N operations on crash\n",
    "- **Production Alternative**: PostgreSQL + pgvector with write-ahead logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence Status:\n",
      "{\n",
      "  \"enabled\": true,\n",
      "  \"snapshot_exists\": true,\n",
      "  \"operations_since_save\": 0,\n",
      "  \"snapshot_info\": {\n",
      "    \"exists\": true,\n",
      "    \"path\": \"/app/data/snapshot.json\",\n",
      "    \"size_bytes\": 7400,\n",
      "    \"last_modified\": \"2025-11-04T21:21:40.566651\"\n",
      "  },\n",
      "  \"save_threshold\": -1,\n",
      "  \"stats\": {\n",
      "    \"libraries\": 3,\n",
      "    \"documents\": 16,\n",
      "    \"chunks\": 22\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Check current persistence status\n",
    "status = client.get_persistence_status()\n",
    "\n",
    "print(\"Persistence Status:\")\n",
    "print(json.dumps(status, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Restore Demo\n",
    "\n",
    "Demonstrate persistence by saving a snapshot, performing a destructive operation, then restoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Snapshot saved successfully\",\n",
      "  \"snapshot_path\": \"/app/data/snapshot.json\",\n",
      "  \"timestamp\": \"2025-11-05T14:48:39.187521\",\n",
      "  \"stats\": {\n",
      "    \"libraries\": 3,\n",
      "    \"documents\": 16,\n",
      "    \"chunks\": 22\n",
      "  },\n",
      "  \"snapshot_info\": {\n",
      "    \"exists\": true,\n",
      "    \"path\": \"/app/data/snapshot.json\",\n",
      "    \"size_bytes\": 21087,\n",
      "    \"last_modified\": \"2025-11-05T14:48:39.123082\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save current state\n",
    "result = client.save_snapshot()\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After delete - Libraries: 2\n"
     ]
    }
   ],
   "source": [
    "# Delete the library (destructive operation)\n",
    "client.delete_library(library_id=library.id)\n",
    "\n",
    "libraries_after_delete = client.list_libraries()\n",
    "print(f\"After delete - Libraries: {len(libraries_after_delete)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification - Libraries: 3\n",
      "  tech_articles (d9ecebd5-0a6c-48dd-ab36-80768c5d13d8)\n",
      "  my_demo_library (84aed1c8-9272-4a35-8f7e-e0e47f231212)\n",
      "  tech_articles (5fbbba2b-ca18-4ad0-8aae-a652c3a5de76)\n"
     ]
    }
   ],
   "source": [
    "# Restore from snapshot\n",
    "result = client.restore_snapshot()\n",
    "\n",
    "# Verify restoration\n",
    "libraries_after_restore = client.list_libraries()\n",
    "print(f\"\\nVerification - Libraries: {len(libraries_after_restore)}\")\n",
    "for lib in libraries_after_restore:\n",
    "    print(f\"  {lib.name} ({lib.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Real-World Integration: Agno RAG Agent\n",
    "\n",
    "This section demonstrates integration with the [Agno](https://github.com/agno-ai/agno) agent framework for building RAG (Retrieval-Augmented Generation) applications.\n",
    "\n",
    "**RAG Pattern**:\n",
    "1. User asks a question\n",
    "2. Agent searches vector DB for relevant context\n",
    "3. Context augments the LLM prompt\n",
    "4. LLM generates informed response\n",
    "\n",
    "**Why This Works**: The hierarchical design (libraries/documents/chunks) naturally maps to knowledge organization, making integration straightforward.\n",
    "\n",
    "See `examples/agno_example.py` for a complete working implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example integration pattern (see agno_example.py for full code)\n",
    "\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.knowledge.knowledge import Knowledge\n",
    "from agno.models.anthropic import Claude\n",
    "from my_vector_db.db import MyVectorDB\n",
    "\n",
    "# Create vector database connection\n",
    "vector_db = MyVectorDB(\n",
    "    api_base_url=\"http://localhost:8000\",\n",
    "    library_name=\"Python Programming Guide\",\n",
    "    index_type=\"flat\",\n",
    ")\n",
    "\n",
    "# Create knowledge base that uses our vector DB\n",
    "knowledge = Knowledge(name=\"Tech Knowledge Base\", vector_db=vector_db, max_results=5)\n",
    "\n",
    "# Create agent with RAG capabilities\n",
    "agent = Agent(\n",
    "    name=\"Tech Assistant\",\n",
    "    knowledge=knowledge,\n",
    "    model=Claude(id=\"claude-sonnet-4-5\"),\n",
    "    search_knowledge=True,  # Enable RAG\n",
    ")\n",
    "\n",
    "# Start interactive CLI (agent searches vector DB automatically)\n",
    "agent.print_response(\n",
    "    \"what are the latest trends in AI and cloud computing?\", stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Design Patterns & Best Practices\n",
    "\n",
    "This section summarizes key design decisions and recommended practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Batch Operations Pattern\n",
    "\n",
    "**Recommended**:\n",
    "```python\n",
    "chunks = client.add_chunks(document_id=doc.id, chunks=large_list)\n",
    "```\n",
    "\n",
    "**Avoid**:\n",
    "```python\n",
    "for chunk in large_list:\n",
    "    client.create_chunk(...)  # Many HTTP round-trips\n",
    "```\n",
    "\n",
    "**Takeaway**: Batch operations reduce network overhead and enable atomic transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(id=UUID('3c2756eb-ad87-41b9-94de-d5ec6123ae50'), text='The quick brown fox jumps over the lazy dog', embedding=[0.1, 0.2, 0.3, 0.4, 0.5], metadata={'source': 'example', 'position': 1}, document_id=UUID('184958ac-c6d4-4fc6-9162-cda31d8bc6a8'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 57, 386167), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 57, 386167)),\n",
       " Chunk(id=UUID('aaec4d6d-c055-4584-b076-b07244aec08d'), text='A fast red bird flies through the clear blue sky', embedding=[0.9, 0.1, 0.5, 0.3, 0.7], metadata={'source': 'example', 'position': 2}, document_id=UUID('184958ac-c6d4-4fc6-9162-cda31d8bc6a8'), created_at=datetime.datetime(2025, 11, 5, 14, 48, 57, 386191), updated_at=datetime.datetime(2025, 11, 5, 14, 48, 57, 386191))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_vector_db import Chunk\n",
    "\n",
    "demo_doc = client.create_document(\n",
    "    library_id=library.id,\n",
    "    name=\"demo_document\",\n",
    "    metadata={\"purpose\": \"demo\"},\n",
    ")\n",
    "\n",
    "# Define chunks with Chunk objects\n",
    "demo_chunks = [\n",
    "    Chunk(\n",
    "        document_id=demo_doc.id,\n",
    "        text=\"The quick brown fox jumps over the lazy dog\",\n",
    "        embedding=[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        metadata={\"source\": \"example\", \"position\": 1}\n",
    "    ),\n",
    "    Chunk(\n",
    "        document_id=demo_doc.id,\n",
    "        text=\"A fast red bird flies through the clear blue sky\",\n",
    "        embedding=[0.9, 0.1, 0.5, 0.3, 0.7],\n",
    "        metadata={\"source\": \"example\", \"position\": 2}\n",
    "    )\n",
    "]\n",
    "\n",
    "client.add_chunks(chunks=demo_chunks, document_id=demo_doc.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Architecture\n",
    "\n",
    "**Layers**: API â†’ Service â†’ Storage â†’ Index\n",
    "\n",
    "**Benefits**:\n",
    "- **Separation of concerns**: Each layer has clear responsibilities\n",
    "- **Testable**: Can test each layer in isolation\n",
    "- **Extensible**: Can swap implementations without affecting other layers\n",
    "\n",
    "\n",
    "#### Key Design Principles\n",
    "\n",
    "1. **Layered Architecture**: Clean separation (API â†’ Service â†’ Storage â†’ Index)\n",
    "2. **Thread-Safe**: RLock-based synchronization for concurrent operations\n",
    "3. **Type-Safe**: Full Pydantic validation throughout\n",
    "4. **Persistence**: JSON snapshots with atomic writes\n",
    "5. **Filtering**: Post-filtering strategy with declarative and custom options\n",
    "\n",
    "![image.png](../docs/api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Index Selection: FLAT vs HNSW\n",
    "\n",
    "| Metric | Flat Index | HNSW Index |\n",
    "|--------|------------|------------|\n",
    "| Search | O(n) - exact | O(log n) - approximate |\n",
    "| Insert | O(1) | O(log n) |\n",
    "| Recall | 100% | 95-99% (tunable) |\n",
    "| Best For | <10K vectors | Millions of vectors |\n",
    "\n",
    "**Recommendation**: Start with FLAT for accuracy and simplicity. Migrate to HNSW when dataset grows beyond 10,000 vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Post-Filtering Strategy\n",
    "\n",
    "**Algorithm**:\n",
    "1. Perform kNN vector search â†’ get candidates\n",
    "2. Fetch full chunk data from storage\n",
    "3. Apply metadata filters\n",
    "4. Return top k results\n",
    "\n",
    "**Tradeoff**: \n",
    "- **Pro**: Simple implementation, works with any index type\n",
    "- **Pro**: Index layer doesn't need filter logic\n",
    "- **Con**: May not return k results if filters are highly selective\n",
    "- **Con**: Requires over-fetching (kÃ—3 for custom filters)\n",
    "\n",
    "**Production Alternative**: Pre-filtering with bitmap indexes for highly selective queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Type Safety Throughout\n",
    "\n",
    "**Pattern**: Pydantic models everywhere\n",
    "```python\n",
    "library: Library = client.create_library(...)  # Type-checked\n",
    "document: Document = client.create_document(...)  # Validated\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Runtime validation catches errors early\n",
    "- IDE autocomplete improves developer experience\n",
    "- Auto-generated OpenAPI documentation\n",
    "- Prevents entire classes of bugs\n",
    "\n",
    "**Tradeoff**: Slight performance overhead (~10-15%), but worth it for reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Architecture\n",
    "\n",
    "**Layers**: API â†’ Service â†’ Storage â†’ Index\n",
    "\n",
    "**Benefits**:\n",
    "- **Separation of concerns**: Each layer has clear responsibilities\n",
    "- **Testable**: Can test each layer in isolation\n",
    "- **Extensible**: Can swap implementations without affecting other layers\n",
    "\n",
    "\n",
    "#### Key Design Principles\n",
    "\n",
    "1. **Layered Architecture**: Clean separation (API â†’ Service â†’ Storage â†’ Index)\n",
    "2. **Thread-Safe**: RLock-based synchronization for concurrent operations\n",
    "3. **Type-Safe**: Full Pydantic validation throughout\n",
    "4. **Persistence**: JSON snapshots with atomic writes\n",
    "5. **Filtering**: Post-filtering strategy with declarative and custom options\n",
    "\n",
    "![image.png](../docs/api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Pragmatic Design Choices\n",
    "\n",
    "| Feature | Current | Production Alternative |\n",
    "|---------|---------|------------------------|\n",
    "| Persistence | JSON snapshots | PostgreSQL + WAL |\n",
    "| Filtering | Post-filtering | Pre-filtering with bitmaps |\n",
    "| Index | FLAT (O(n)) | HNSW (O(log n)) |\n",
    "| Locking | Coarse RLock | Fine-grained locks |\n",
    "| Storage | In-memory | Distributed (Redis, etc.) |\n",
    "\n",
    "**Philosophy**: Start simple, scale where needed.\n",
    "\n",
    "The current design is:\n",
    "- Easy to understand and debug\n",
    "- Production-ready for moderate scale (<100K vectors)\n",
    "- Extensible for larger scale with clear upgrade paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client connection closed\n"
     ]
    }
   ],
   "source": [
    "# Close client connection\n",
    "client.delete_library(library_id=library.id)  # Clean up\n",
    "client.close()\n",
    "print(\"Client connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **API Documentation**: http://localhost:8000/docs\n",
    "2. **SDK Reference**: `docs/README.md`\n",
    "3. **More Examples**: `examples/` directory\n",
    "4. **Run Tests**: `uv run pytest`\n",
    "\n",
    "**Discussion Questions**:\n",
    "- When would you switch from FLAT to HNSW index?\n",
    "- How would you implement distributed storage?\n",
    "- What monitoring and observability would you add?\n",
    "- How would you handle schema migrations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-vector-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
