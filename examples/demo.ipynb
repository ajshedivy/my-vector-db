{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Vector Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture Overview <a id=\"architecture\"></a>\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "1. **Layered Architecture**: Clean separation of concerns (API → Service → Storage → Index)\n",
    "2. **Thread-Safe**: RLock-based synchronization for concurrent operations\n",
    "3. **Type-Safe**: Full Pydantic models with validation\n",
    "4. **Persistence**: Periodic JSON snapshots with atomic writes\n",
    "5. **Filtering**: Post-filtering strategy with over-fetch mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup & Connection <a id=\"setup\"></a>\n",
    "\n",
    "First, ensure the Vector Database API is running:\n",
    "```bash\n",
    "docker compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to Vector Database API\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.sdk import VectorDBClient\n",
    "\n",
    "# Initialize client\n",
    "client = VectorDBClient(base_url=\"http://localhost:8000\")\n",
    "print(\"✓ Connected to Vector Database API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Client Operations <a id=\"crud\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created library: 00fa6322-88ad-4f27-bfa6-1a0802acd19d\n",
      "  Name: tech_articles\n",
      "  Index: IndexType.FLAT\n",
      "  Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# Create a library (collection of documents)\n",
    "library = client.create_library(\n",
    "    name=\"tech_articles\",\n",
    "    index_type=\"flat\",  # Options: 'flat', 'hnsw'\n",
    "    index_config={\"metric\": \"cosine\"},  # Options: 'cosine', 'euclidean', 'dot_product'\n",
    "    metadata={\"description\": \"Technology articles dataset\", \"version\": \"1.0\"},\n",
    ")\n",
    "\n",
    "print(f\"✓ Created library: {library.id}\")\n",
    "print(f\"  Name: {library.name}\")\n",
    "print(f\"  Index: {library.index_type}\")\n",
    "print(f\"  Metric: {library.index_config['metric']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created document: 3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5\n",
      "  Name: tech_articles_2024\n",
      "  Library: 00fa6322-88ad-4f27-bfa6-1a0802acd19d\n"
     ]
    }
   ],
   "source": [
    "# Create a document (logical grouping of chunks)\n",
    "document = client.create_document(\n",
    "    library_id=library.id,\n",
    "    name=\"tech_articles_2024\",\n",
    "    metadata={\"year\": 2024, \"source\": \"tech blogs\"},\n",
    ")\n",
    "\n",
    "print(f\"✓ Created document: {document.id}\")\n",
    "print(f\"  Name: {document.name}\")\n",
    "print(f\"  Library: {document.library_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset\n",
    "\n",
    "We'll use a curated dataset of technology articles with:\n",
    "- Multiple categories (AI, Cloud, Security)\n",
    "- Varying confidence scores\n",
    "- Different authors\n",
    "- 5-dimensional embeddings (simplified for demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 7 articles for insertion\n"
     ]
    }
   ],
   "source": [
    "# Sample articles with embeddings and metadata\n",
    "articles = [\n",
    "    # AI/ML articles\n",
    "    {\n",
    "        \"text\": \"Machine learning models use neural networks for pattern recognition\",\n",
    "        \"embedding\": [0.9, 0.8, 0.1, 0.2, 0.3],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"machine learning\",\n",
    "            \"confidence\": 0.95,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Deep learning architectures enable complex AI applications\",\n",
    "        \"embedding\": [0.85, 0.75, 0.15, 0.25, 0.35],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"deep learning\",\n",
    "            \"confidence\": 0.88,\n",
    "            \"author\": \"Bob\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Reinforcement learning enables autonomous decision making\",\n",
    "        \"embedding\": [0.87, 0.77, 0.13, 0.23, 0.33],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"ai\",\n",
    "            \"topic\": \"reinforcement learning\",\n",
    "            \"confidence\": 0.90,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    # Cloud computing articles\n",
    "    {\n",
    "        \"text\": \"Cloud infrastructure provides scalable computing resources\",\n",
    "        \"embedding\": [0.3, 0.2, 0.9, 0.8, 0.1],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"cloud\",\n",
    "            \"topic\": \"infrastructure\",\n",
    "            \"confidence\": 0.92,\n",
    "            \"author\": \"Charlie\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Kubernetes orchestrates containerized applications in the cloud\",\n",
    "        \"embedding\": [0.35, 0.25, 0.85, 0.75, 0.15],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"cloud\",\n",
    "            \"topic\": \"kubernetes\",\n",
    "            \"confidence\": 0.89,\n",
    "            \"author\": \"Alice\",\n",
    "        },\n",
    "    },\n",
    "    # Security articles\n",
    "    {\n",
    "        \"text\": \"Cybersecurity best practices protect against data breaches\",\n",
    "        \"embedding\": [0.1, 0.2, 0.3, 0.9, 0.8],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"security\",\n",
    "            \"topic\": \"cybersecurity\",\n",
    "            \"confidence\": 0.91,\n",
    "            \"author\": \"Bob\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Machine learning detects anomalies in network security\",\n",
    "        \"embedding\": [0.6, 0.5, 0.4, 0.7, 0.6],\n",
    "        \"metadata\": {\n",
    "            \"category\": \"security\",\n",
    "            \"topic\": \"machine learning\",\n",
    "            \"confidence\": 0.82,\n",
    "            \"author\": \"Charlie\",\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(articles)} articles for insertion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Insert with add_chunks()\n",
    "\n",
    "**Design Decision**: Batch operations for efficiency\n",
    "- Single API call instead of multiple requests\n",
    "- Atomic transactions (all-or-nothing)\n",
    "- Better for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Inserted 7 chunks\n",
      "\n",
      "Sample chunk:\n",
      "  ID: bdb78e0f-b8c2-4338-9950-b314be507ea1\n",
      "  Text: Machine learning models use neural networks for pa...\n",
      "  Metadata: {'category': 'ai', 'topic': 'machine learning', 'confidence': 0.95, 'author': 'Alice'}\n"
     ]
    }
   ],
   "source": [
    "# Add all chunks in a single batch operation\n",
    "chunks = client.add_chunks(document_id=document.id, chunks=articles)\n",
    "\n",
    "print(f\"✓ Inserted {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(f\"  ID: {chunks[0].id}\")\n",
    "print(f\"  Text: {chunks[0].text[:50]}...\")\n",
    "print(f\"  Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client methods for working with libraries, documents, and chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Library(id=UUID('00fa6322-88ad-4f27-bfa6-1a0802acd19d'), name='tech_articles', document_ids=[UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5')], metadata={'description': 'Technology articles dataset', 'version': '1.0'}, index_type=<IndexType.FLAT: 'flat'>, index_config={'metric': 'cosine'}, created_at=datetime.datetime(2025, 10, 31, 22, 37, 48, 978691), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 48, 978691))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libraries = client.list_libraries()\n",
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), name='tech_articles_2024', chunk_ids=[UUID('bdb78e0f-b8c2-4338-9950-b314be507ea1'), UUID('d3faf2db-c3ab-453a-a307-3c9152cb191d'), UUID('da84ef24-b029-46c4-9c98-50cd1c57527f'), UUID('5fe03a9e-8fb6-41fe-9fd7-b48135918fe0'), UUID('24f5c889-2215-4a3a-9b30-8e700711be6c'), UUID('986bfa72-788e-49e1-94f5-ab14a2ba103a'), UUID('e57f543b-483c-4c27-be28-10a435eeb255')], metadata={'year': 2024, 'source': 'tech blogs'}, library_id=UUID('00fa6322-88ad-4f27-bfa6-1a0802acd19d'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 50, 838904), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 50, 838904))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = client.list_documents(library_id=library.id)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(id=UUID('bdb78e0f-b8c2-4338-9950-b314be507ea1'), text='Machine learning models use neural networks for pattern recognition', embedding=[0.9, 0.8, 0.1, 0.2, 0.3], metadata={'category': 'ai', 'topic': 'machine learning', 'confidence': 0.95, 'author': 'Alice'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379313), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379313)),\n",
       " Chunk(id=UUID('d3faf2db-c3ab-453a-a307-3c9152cb191d'), text='Deep learning architectures enable complex AI applications', embedding=[0.85, 0.75, 0.15, 0.25, 0.35], metadata={'category': 'ai', 'topic': 'deep learning', 'confidence': 0.88, 'author': 'Bob'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379329), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379329)),\n",
       " Chunk(id=UUID('da84ef24-b029-46c4-9c98-50cd1c57527f'), text='Reinforcement learning enables autonomous decision making', embedding=[0.87, 0.77, 0.13, 0.23, 0.33], metadata={'category': 'ai', 'topic': 'reinforcement learning', 'confidence': 0.9, 'author': 'Alice'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379337), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379337)),\n",
       " Chunk(id=UUID('5fe03a9e-8fb6-41fe-9fd7-b48135918fe0'), text='Cloud infrastructure provides scalable computing resources', embedding=[0.3, 0.2, 0.9, 0.8, 0.1], metadata={'category': 'cloud', 'topic': 'infrastructure', 'confidence': 0.92, 'author': 'Charlie'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379344), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379344)),\n",
       " Chunk(id=UUID('24f5c889-2215-4a3a-9b30-8e700711be6c'), text='Kubernetes orchestrates containerized applications in the cloud', embedding=[0.35, 0.25, 0.85, 0.75, 0.15], metadata={'category': 'cloud', 'topic': 'kubernetes', 'confidence': 0.89, 'author': 'Alice'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379350), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379350)),\n",
       " Chunk(id=UUID('986bfa72-788e-49e1-94f5-ab14a2ba103a'), text='Cybersecurity best practices protect against data breaches', embedding=[0.1, 0.2, 0.3, 0.9, 0.8], metadata={'category': 'security', 'topic': 'cybersecurity', 'confidence': 0.91, 'author': 'Bob'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379357), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379357)),\n",
       " Chunk(id=UUID('e57f543b-483c-4c27-be28-10a435eeb255'), text='Machine learning detects anomalies in network security', embedding=[0.6, 0.5, 0.4, 0.7, 0.6], metadata={'category': 'security', 'topic': 'machine learning', 'confidence': 0.82, 'author': 'Charlie'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379363), updated_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379363))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = client.list_chunks(document.id)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update chunk: bdb78e0f-b8c2-4338-9950-b314be507ea1\n",
      "update chunk: d3faf2db-c3ab-453a-a307-3c9152cb191d\n",
      "update chunk: da84ef24-b029-46c4-9c98-50cd1c57527f\n",
      "update chunk: 5fe03a9e-8fb6-41fe-9fd7-b48135918fe0\n",
      "update chunk: 24f5c889-2215-4a3a-9b30-8e700711be6c\n",
      "update chunk: 986bfa72-788e-49e1-94f5-ab14a2ba103a\n",
      "update chunk: e57f543b-483c-4c27-be28-10a435eeb255\n"
     ]
    }
   ],
   "source": [
    "# lets uppdate all chunks with new metadata\n",
    "for chunk in client.list_chunks(document_id=document.id):\n",
    "    print(f\"update chunk: {chunk.id}\")\n",
    "\n",
    "    # update the metadata on the chunk object\n",
    "    chunk.metadata[\"reviewed_by\"] = \"the code bot\"\n",
    "    client.update_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(id=UUID('bdb78e0f-b8c2-4338-9950-b314be507ea1'), text='Machine learning models use neural networks for pattern recognition', embedding=[0.9, 0.8, 0.1, 0.2, 0.3], metadata={'category': 'ai', 'topic': 'machine learning', 'confidence': 0.95, 'author': 'Alice', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379313), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 900990)),\n",
       " Chunk(id=UUID('d3faf2db-c3ab-453a-a307-3c9152cb191d'), text='Deep learning architectures enable complex AI applications', embedding=[0.85, 0.75, 0.15, 0.25, 0.35], metadata={'category': 'ai', 'topic': 'deep learning', 'confidence': 0.88, 'author': 'Bob', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379329), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 902480)),\n",
       " Chunk(id=UUID('da84ef24-b029-46c4-9c98-50cd1c57527f'), text='Reinforcement learning enables autonomous decision making', embedding=[0.87, 0.77, 0.13, 0.23, 0.33], metadata={'category': 'ai', 'topic': 'reinforcement learning', 'confidence': 0.9, 'author': 'Alice', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379337), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 903667)),\n",
       " Chunk(id=UUID('5fe03a9e-8fb6-41fe-9fd7-b48135918fe0'), text='Cloud infrastructure provides scalable computing resources', embedding=[0.3, 0.2, 0.9, 0.8, 0.1], metadata={'category': 'cloud', 'topic': 'infrastructure', 'confidence': 0.92, 'author': 'Charlie', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379344), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 905086)),\n",
       " Chunk(id=UUID('24f5c889-2215-4a3a-9b30-8e700711be6c'), text='Kubernetes orchestrates containerized applications in the cloud', embedding=[0.35, 0.25, 0.85, 0.75, 0.15], metadata={'category': 'cloud', 'topic': 'kubernetes', 'confidence': 0.89, 'author': 'Alice', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379350), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 906242)),\n",
       " Chunk(id=UUID('986bfa72-788e-49e1-94f5-ab14a2ba103a'), text='Cybersecurity best practices protect against data breaches', embedding=[0.1, 0.2, 0.3, 0.9, 0.8], metadata={'category': 'security', 'topic': 'cybersecurity', 'confidence': 0.91, 'author': 'Bob', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379357), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 907826)),\n",
       " Chunk(id=UUID('e57f543b-483c-4c27-be28-10a435eeb255'), text='Machine learning detects anomalies in network security', embedding=[0.6, 0.5, 0.4, 0.7, 0.6], metadata={'category': 'security', 'topic': 'machine learning', 'confidence': 0.82, 'author': 'Charlie', 'reviewed_by': 'the code bot'}, document_id=UUID('3fa0fb29-2bdb-43f3-b2b0-4815e69d6cc5'), created_at=datetime.datetime(2025, 10, 31, 22, 37, 55, 379363), updated_at=datetime.datetime(2025, 10, 31, 22, 40, 0, 909137))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_chunks(document_id=document.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector Search <a id=\"search\"></a>\n",
    "\n",
    "### Search Algorithm: kNN with Cosine Similarity\n",
    "\n",
    "**Design Decision**: Post-filtering strategy\n",
    "1. Perform vector search on index\n",
    "2. Retrieve full chunk data\n",
    "3. Apply metadata filters\n",
    "4. Return top k results\n",
    "\n",
    "**Tradeoff**: Simple implementation vs. optimal performance for highly selective filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query time: 2.20ms\n",
      "\n",
      "Top 5 results:\n",
      "\n",
      "1. Score: 0.9999\n",
      "   Text: Reinforcement learning enables autonomous decision making\n",
      "   Category: ai\n",
      "   Author: Alice\n",
      "\n",
      "2. Score: 0.9995\n",
      "   Text: Machine learning models use neural networks for pattern recognition\n",
      "   Category: ai\n",
      "   Author: Alice\n",
      "\n",
      "3. Score: 0.9987\n",
      "   Text: Deep learning architectures enable complex AI applications\n",
      "   Category: ai\n",
      "   Author: Bob\n",
      "\n",
      "4. Score: 0.8285\n",
      "   Text: Machine learning detects anomalies in network security\n",
      "   Category: security\n",
      "   Author: Charlie\n",
      "\n",
      "5. Score: 0.5382\n",
      "   Text: Kubernetes orchestrates containerized applications in the cloud\n",
      "   Category: cloud\n",
      "   Author: Alice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic vector search\n",
    "query_vector = [0.88, 0.78, 0.12, 0.22, 0.32]  # Query about AI/ML\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,  # Return top 5 results\n",
    ")\n",
    "\n",
    "print(f\"Query time: {results.query_time_ms:.2f}ms\")\n",
    "print(f\"\\nTop {len(results.results)} results:\\n\")\n",
    "\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. Score: {result.score:.4f}\")\n",
    "    print(f\"   Text: {result.text}\")\n",
    "    print(f\"   Category: {result.metadata['category']}\")\n",
    "    print(f\"   Author: {result.metadata['author']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Filtering <a id=\"filtering\"></a>\n",
    "\n",
    "### Declarative Metadata Filtering\n",
    "\n",
    "**Design Decision**: Two filtering approaches\n",
    "1. **Declarative filters** (API-compatible): JSON-serializable filter definitions\n",
    "2. **Custom Python functions** (SDK-only): Flexible client-side filtering\n",
    "\n",
    "Both support complex logic (AND/OR operators, nested conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by category='ai':\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making... (score: 0.9999)\n",
      "2. Machine learning models use neural networks for pattern reco... (score: 0.9995)\n",
      "3. Deep learning architectures enable complex AI applications... (score: 0.9987)\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.domain.models import (\n",
    "    SearchFilters,\n",
    "    FilterGroup,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    "    LogicalOperator,\n",
    ")\n",
    "\n",
    "# Example 1: Simple metadata filter\n",
    "filters = SearchFilters(\n",
    "    metadata=FilterGroup(\n",
    "        operator=LogicalOperator.AND,\n",
    "        filters=[\n",
    "            MetadataFilter(field=\"category\", operator=FilterOperator.EQUALS, value=\"ai\")\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id, embedding=query_vector, k=5, filters=filters\n",
    ")\n",
    "\n",
    "print(\"Filtered by category='ai':\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text[:60]}... (score: {result.score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered by (AI AND confidence>0.9) OR security:\n",
      "\n",
      "1. [ai] Machine learning models use neural networks for pa...\n",
      "   Confidence: 0.95, Score: 0.9995\n",
      "\n",
      "2. [security] Machine learning detects anomalies in network secu...\n",
      "   Confidence: 0.82, Score: 0.8285\n",
      "\n",
      "3. [security] Cybersecurity best practices protect against data ...\n",
      "   Confidence: 0.91, Score: 0.4679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Complex AND/OR filter\n",
    "complex_filters = SearchFilters(\n",
    "    metadata=FilterGroup(\n",
    "        operator=LogicalOperator.OR,\n",
    "        filters=[\n",
    "            # High-confidence AI articles\n",
    "            FilterGroup(\n",
    "                operator=LogicalOperator.AND,\n",
    "                filters=[\n",
    "                    MetadataFilter(\n",
    "                        field=\"category\", operator=FilterOperator.EQUALS, value=\"ai\"\n",
    "                    ),\n",
    "                    MetadataFilter(\n",
    "                        field=\"confidence\",\n",
    "                        operator=FilterOperator.GREATER_THAN,\n",
    "                        value=0.9,\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "            # OR any security article\n",
    "            MetadataFilter(\n",
    "                field=\"category\", operator=FilterOperator.EQUALS, value=\"security\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id, embedding=query_vector, k=10, filters=complex_filters\n",
    ")\n",
    "\n",
    "print(\"Filtered by (AI AND confidence>0.9) OR security:\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. [{result.metadata['category']}] {result.text[:50]}...\")\n",
    "    print(f\"   Confidence: {result.metadata['confidence']}, Score: {result.score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Filter Functions (SDK Only)\n",
    "\n",
    "**Design Decision**: Client-side custom filtering\n",
    "- Filter functions receive `SearchResult` objects (not `Chunk`)\n",
    "- Over-fetch strategy (k×3) to compensate for filtering\n",
    "- Enables complex text analysis, score-based filtering, etc.\n",
    "\n",
    "**Tradeoff**: More network transfer, but maximum flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom filter (score>0.95, AI, Alice, confidence>0.85):\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making\n",
      "   Score: 0.9999, Confidence: 0.9\n",
      "\n",
      "2. Machine learning models use neural networks for pattern recognition\n",
      "   Score: 0.9995, Confidence: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_vector_db.sdk.models import SearchResult\n",
    "\n",
    "\n",
    "# Custom filter: High-quality AI articles by Alice\n",
    "def quality_ai_by_alice(result: SearchResult) -> bool:\n",
    "    \"\"\"\n",
    "    Custom filter that combines:\n",
    "    - High similarity score (>0.95)\n",
    "    - AI category\n",
    "    - Author is Alice\n",
    "    - High confidence (>0.85)\n",
    "    \"\"\"\n",
    "    return (\n",
    "        result.score > 0.95\n",
    "        and result.metadata.get(\"category\") == \"ai\"\n",
    "        and result.metadata.get(\"author\") == \"Alice\"\n",
    "        and result.metadata.get(\"confidence\", 0) > 0.85\n",
    "    )\n",
    "\n",
    "\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filter_function=quality_ai_by_alice,  # Pass function directly!\n",
    ")\n",
    "\n",
    "print(\"Custom filter (score>0.95, AI, Alice, confidence>0.85):\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text}\")\n",
    "    print(f\"   Score: {result.score:.4f}, Confidence: {result.metadata['confidence']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda filter (text contains 'learning'):\n",
      "\n",
      "1. Reinforcement learning enables autonomous decision making\n",
      "2. Machine learning models use neural networks for pattern recognition\n",
      "3. Deep learning architectures enable complex AI applications\n",
      "4. Machine learning detects anomalies in network security\n"
     ]
    }
   ],
   "source": [
    "# Lambda filter: Articles mentioning \"learning\"\n",
    "results = client.search(\n",
    "    library_id=library.id,\n",
    "    embedding=query_vector,\n",
    "    k=5,\n",
    "    filter_function=lambda result: \"learning\" in result.text.lower(),\n",
    ")\n",
    "\n",
    "print(\"Lambda filter (text contains 'learning'):\\n\")\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Operations <a id=\"batch\"></a>\n",
    "\n",
    "### Performance Comparison: Single vs Batch Inserts\n",
    "\n",
    "**Design Decision**: Batch API for efficiency\n",
    "- Reduces HTTP round-trips\n",
    "- Atomic transactions\n",
    "- Better for production workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create test document\n",
    "test_doc = client.create_document(library_id=library.id, name=\"batch_test\")\n",
    "\n",
    "# Generate test data\n",
    "test_chunks = [\n",
    "    {\n",
    "        \"text\": f\"Test article number {i}\",\n",
    "        \"embedding\": [0.1 * i, 0.2 * i, 0.3 * i, 0.4 * i, 0.5 * i],\n",
    "        \"metadata\": {\"index\": i},\n",
    "    }\n",
    "    for i in range(1, 11)\n",
    "]\n",
    "\n",
    "# Batch insert\n",
    "start = time.time()\n",
    "client.add_chunks(document_id=test_doc.id, chunks=test_chunks)\n",
    "batch_time = time.time() - start\n",
    "\n",
    "print(f\"Batch insert (10 chunks): {batch_time * 1000:.2f}ms\")\n",
    "print(f\"Throughput: {len(test_chunks) / batch_time:.1f} chunks/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 1.2,\n",
       " 1.6,\n",
       " 2.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.1 * i, 0.2 * i, 0.3 * i, 0.4 * i, 0.5 * i] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Persistence & Durability <a id=\"persistence\"></a>\n",
    "\n",
    "### Persistence Strategy: Periodic JSON Snapshots\n",
    "\n",
    "**Design Decision**: Simple periodic snapshots\n",
    "- Saves entire state to JSON every N operations (default: 10)\n",
    "- Atomic writes (temp file + rename)\n",
    "- Configurable via environment variables\n",
    "\n",
    "**Architecture**:\n",
    "```python\n",
    "# In storage.py - no circular dependencies!\n",
    "from serialization import serialize_to_json\n",
    "\n",
    "def save_snapshot(self):\n",
    "    serialize_to_json(libraries, documents, chunks, path)\n",
    "```\n",
    "\n",
    "**Tradeoff**: Simplicity vs WAL-based durability\n",
    "- ✅ Easy to understand and debug\n",
    "- ✅ Human-readable JSON format\n",
    "- ✅ No threading complexity\n",
    "- ⚠️ May lose last N operations on crash\n",
    "\n",
    "### Check Persistence Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all libraries (will show persistence working across restarts)\n",
    "libraries = client.list_libraries()\n",
    "\n",
    "print(f\"Total libraries: {len(libraries)}\\n\")\n",
    "for lib in libraries:\n",
    "    print(f\"Library: {lib.name}\")\n",
    "    print(f\"  ID: {lib.id}\")\n",
    "    print(f\"  Documents: {len(lib.document_ids)}\")\n",
    "    print(f\"  Index: {lib.index_type}\")\n",
    "    for doc_id in lib.document_ids:\n",
    "        doc = client.get_document(document_id=doc_id)\n",
    "        print(f\"    Document: {doc.name} (ID: {doc.id}) - Chunks: {len(doc.chunk_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total libraries: {len(libraries)}\\n\")\n",
    "for lib in libraries:\n",
    "    print(f\"Library: {lib.name}\")\n",
    "    print(f\"  ID: {lib.id}\")\n",
    "    print(f\"  Documents: {len(lib.document_ids)}\")\n",
    "    print(f\"  Index: {lib.index_type}\")\n",
    "    for doc_id in lib.document_ids:\n",
    "        doc = client.get_document(document_id=doc_id)\n",
    "        print(f\"    Document: {doc.name} (ID: {doc.id}) - Chunks: {len(doc.chunk_ids)}\")\n",
    "        for chunk_id in doc.chunk_ids:\n",
    "            chunk = client.get_chunk(chunk_id=chunk_id)\n",
    "            print(f\"      Chunk ID: {chunk.id} - Text: {chunk.text[:30]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total libraries: {len(libraries)}\\n\")\n",
    "for lib in libraries:\n",
    "    print(f\"Library: {lib.name}\")\n",
    "    print(f\"  ID: {lib.id}\")\n",
    "    print(f\"  Documents: {len(lib.document_ids)}\")\n",
    "    print(f\"  Index: {lib.index_type}\")\n",
    "    for doc_id in lib.document_ids:\n",
    "        doc = client.get_document(document_id=doc_id)\n",
    "        print(f\"    Document: {doc.name} (ID: {doc.id}) - Chunks: {len(doc.chunk_ids)}\")\n",
    "        client.update_document(document_id=doc.id, name=doc.name + \"_updated\")\n",
    "\n",
    "\n",
    "for lib in libraries:\n",
    "    print(f\"Library: {lib.name}\")\n",
    "    print(f\"  ID: {lib.id}\")\n",
    "    print(f\"  Documents: {len(lib.document_ids)}\")\n",
    "    print(f\"  Index: {lib.index_type}\")\n",
    "    for doc_id in lib.document_ids:\n",
    "        doc = client.get_document(document_id=doc_id)\n",
    "        print(f\"    Document: {doc.name} (ID: {doc.id}) - Chunks: {len(doc.chunk_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Configuration for Persistence\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "environment:\n",
    "  - ENABLE_PERSISTENCE=true\n",
    "  - PERSISTENCE_DIR=/app/data\n",
    "  - PERSISTENCE_SAVE_EVERY=10  # Save every 10 operations\n",
    "volumes:\n",
    "  - ./data:/app/data  # Persist across restarts\n",
    "```\n",
    "\n",
    "**Test**: Restart the Docker container and re-run this notebook - data will be preserved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.save_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_library(library_id=library.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.list_libraries())\n",
    "\n",
    "client.restore_snapshot()\n",
    "libraries = client.list_libraries()\n",
    "print(f\"Total libraries: {len(libraries)}\\n\")\n",
    "for lib in libraries:\n",
    "    print(f\"Library: {lib.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Design Decisions & Tradeoffs <a id=\"design\"></a>\n",
    "\n",
    "### 1. Layered Architecture\n",
    "\n",
    "**Decision**: Separate concerns into layers (API → Service → Storage → Index)\n",
    "\n",
    "**Pros**:\n",
    "- Clean separation of concerns\n",
    "- Easy to test each layer independently\n",
    "- Can swap implementations (e.g., different indexes)\n",
    "\n",
    "**Cons**:\n",
    "- More code\n",
    "- Slight performance overhead from abstraction\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Post-Filtering Strategy\n",
    "\n",
    "**Decision**: Apply metadata filters AFTER vector search\n",
    "\n",
    "```python\n",
    "# Algorithm\n",
    "1. kNN search → get candidates\n",
    "2. Fetch chunk data\n",
    "3. Apply filters\n",
    "4. Return top k\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- Simple implementation\n",
    "- Index layer doesn't need filter logic\n",
    "- Works with any index type\n",
    "\n",
    "**Cons**:\n",
    "- May not return k results if filters are very selective\n",
    "- Requires over-fetching (k×3)\n",
    "\n",
    "**Production Alternative**: Pre-filtering with bitmap indexes for highly selective queries\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Flat Index (Current) vs HNSW (Future)\n",
    "\n",
    "| Metric | Flat Index | HNSW Index |\n",
    "|--------|------------|------------|\n",
    "| Search | O(n) - exact | O(log n) - approximate |\n",
    "| Insert | O(1) | O(log n) |\n",
    "| Memory | O(n·d) | O(n·M·log n) |\n",
    "| Recall | 100% | ~95-99% (tunable) |\n",
    "| Best For | <10K vectors | Millions of vectors |\n",
    "\n",
    "**Decision**: Start with Flat, add HNSW for scale\n",
    "\n",
    "---\n",
    "\n",
    "### 4. JSON Persistence vs Database\n",
    "\n",
    "**Decision**: JSON snapshots for take-home assessment\n",
    "\n",
    "**Pros**:\n",
    "- Human-readable\n",
    "- Easy to debug\n",
    "- No external dependencies\n",
    "- Simple implementation (~200 LOC)\n",
    "\n",
    "**Cons**:\n",
    "- Not suitable for production at scale\n",
    "- May lose last N operations\n",
    "\n",
    "**Production Alternative**: PostgreSQL with pgvector, or specialized vector DB like Qdrant\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Thread Safety: RLock\n",
    "\n",
    "**Decision**: Reentrant locks for synchronization\n",
    "\n",
    "```python\n",
    "with self._lock:\n",
    "    # Thread-safe operations\n",
    "    self._libraries[id] = library\n",
    "```\n",
    "\n",
    "**Pros**:\n",
    "- Simple and correct\n",
    "- Allows nested locking (same thread can acquire multiple times)\n",
    "\n",
    "**Cons**:\n",
    "- Coarse-grained locking (entire storage)\n",
    "\n",
    "**Production Alternative**: Fine-grained locking per library or read-write locks\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Type Safety: Pydantic Models\n",
    "\n",
    "**Decision**: Full Pydantic validation throughout\n",
    "\n",
    "**Pros**:\n",
    "- Compile-time and runtime validation\n",
    "- Auto-generated OpenAPI docs\n",
    "- IDE autocomplete\n",
    "\n",
    "**Cons**:\n",
    "- Slight performance overhead\n",
    "- More verbose code\n",
    "\n",
    "**Worth it**: Type safety prevents entire classes of bugs\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Client-Side Custom Filtering\n",
    "\n",
    "**Decision**: Custom filter functions work on `SearchResult`, not `Chunk`\n",
    "\n",
    "**Pros**:\n",
    "- No circular dependencies (domain ↔ SDK)\n",
    "- Access to similarity `score` (only in SearchResult)\n",
    "- No fake data (empty embeddings)\n",
    "\n",
    "**Cons**:\n",
    "- Embedding not available for filtering (acceptable - not typically needed)\n",
    "\n",
    "---\n",
    "\n",
    "### Summary: Pragmatic Tradeoffs for Take-Home Assessment\n",
    "\n",
    "| Feature | Current Approach | Production Alternative |\n",
    "|---------|------------------|------------------------|\n",
    "| Persistence | JSON snapshots | PostgreSQL + WAL |\n",
    "| Filtering | Post-filtering | Pre-filtering with bitmaps |\n",
    "| Index | Flat (O(n)) | HNSW (O(log n)) |\n",
    "| Locking | Coarse RLock | Fine-grained locks |\n",
    "| Storage | In-memory | Distributed (Redis, etc.) |\n",
    "\n",
    "**Philosophy**: Start simple, scale where needed. The current design is:\n",
    "- ✅ Easy to understand\n",
    "- ✅ Demonstrably correct\n",
    "- ✅ Production-ready for moderate scale (<100K vectors)\n",
    "- ✅ Extensible to handle larger scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the demo library\n",
    "# client.delete_library(library_id=library.id)\n",
    "# print(\"✓ Cleaned up demo data\")\n",
    "\n",
    "# Close client connection\n",
    "client.close()\n",
    "print(\"✓ Client connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Explore the API**: Visit http://localhost:8000/docs for interactive Swagger docs\n",
    "2. **Check persistence**: Restart Docker container and re-run to see data preserved\n",
    "3. **Review code**: See `src/my_vector_db/` for implementation details\n",
    "4. **Run tests**: `uv run pytest` to verify all functionality\n",
    "\n",
    "---\n",
    "\n",
    "**Questions for Discussion**:\n",
    "- When would you switch from Flat to HNSW index?\n",
    "- How would you implement distributed storage?\n",
    "- What's your approach to monitoring and observability?\n",
    "- How would you handle schema migrations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-vector-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
